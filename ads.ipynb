{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ADS Independent citation counter\n",
    "\n",
    "In this notebook, I query ADS for independent citations to all of my peer-reviewed publications. I do this by looping over all refereed papers and excluding all authors of that paper from the query. We match on the last name and initials (as does ADS) and use ORCID iD for cross-checking whenever available."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "! date"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sun Aug  8 20:32:17 EDT 2021\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import requests, json\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Enter your API key below. \n",
    "\n",
    "To obtain an API key, you need to be logged in to your ADS account. Sign up for one with your email if you have never logged in. Go to **Account** > **Settings** > **API token** and copy your unique 40-character API key and assign it to the `token` variable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "## Configuration\n",
    "token=\"yOuR-kEy-HeRe\"\n",
    "headers={'Authorization': 'Bearer ' + token}\n",
    "\n",
    "check_orcid = True\n",
    "verbose = False  # Set it to True if you want lengthy outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## Define a convenience function to standardize the names\n",
    "def standardize_names(name):\n",
    "    if not \",\" in name:\n",
    "        return name\n",
    "    try:\n",
    "        lastname, firstname = name.split(',')\n",
    "        initial = firstname[1]\n",
    "        return f\"{lastname},+{initial}\"\n",
    "    except:\n",
    "        # This usually happens for collaboration papers\n",
    "        print(f\"Cannot split '{name}' into first and last names!\")\n",
    "        return name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, query for all refereed papers authored by Kannawadi, Arun"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%%time\n",
    "author=standardize_names('Kannawadi, Arun')\n",
    "\n",
    "base_url = \"https://api.adsabs.harvard.edu/v1/search/query?\"\n",
    "fq = \"property%3Arefereed+property%3Aarticle\"\n",
    "fq = \"property%3Aarticle\"\n",
    "fl = \"author,title,bibcode,citation_count,orcid_pub,orcid_user,orcid_other,property\"\n",
    "rows = 500\n",
    "\n",
    "# the query parameters can be included as part of the URL\n",
    "url = f\"{base_url}q=author%3A{author}&fq={fq}&fl={fl}&rows={rows}\"\n",
    "print(f\"URL = {url}\\n\")\n",
    "r = requests.get(url, headers=headers)\n",
    "# the requests package returns an object; to get just the JSON API response, you have to specify this\n",
    "js = r.json()\n",
    "publications = js['response']['docs']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "URL = https://api.adsabs.harvard.edu/v1/search/query?q=author%3AKannawadi,+A&fq=property%3Aarticle&fl=author,title,bibcode,citation_count,orcid_pub,orcid_user,orcid_other,property&rows=500\n",
      "\n",
      "CPU times: user 24.4 ms, sys: 6.36 ms, total: 30.7 ms\n",
      "Wall time: 624 ms\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## Print the complete list of queried papers\n",
    "print(\"Complete list of queried papers\")\n",
    "print(\"\\t   Bibcode       #Cites \\t Title\\n\")\n",
    "citation_counts = 0\n",
    "for paper in publications:\n",
    "    print(paper['bibcode'], '\\t', paper['citation_count'], '\\t', paper['title'][0])\n",
    "    citation_counts += paper['citation_count']\n",
    "print(\"\\nTotal number of citations = \", citation_counts)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Complete list of queried papers\n",
      "\t   Bibcode       #Cites \t Title\n",
      "\n",
      "2020A&A...633A..69H \t 193 \t KiDS+VIKING-450: Cosmic shear tomography with optical and infrared data\n",
      "2014ApJS..212....5M \t 120 \t The Third Gravitational Lensing Accuracy Testing (GREAT3) Challenge Handbook\n",
      "2021A&A...646A.140H \t 124 \t KiDS-1000 Cosmology: Multi-probe weak gravitational lensing and spectroscopic galaxy clustering constraints\n",
      "2021A&A...645A.104A \t 113 \t KiDS-1000 cosmology: Cosmic shear constraints and comparison between two point statistics\n",
      "2020A&A...638L...1J \t 93 \t KiDS+VIKING-450 and DES-Y1 combined: Cosmology with cosmic shear\n",
      "2020A&A...634A.127A \t 59 \t KiDS+VIKING-450 and DES-Y1 combined: Mitigating baryon feedback uncertainty with COSEBIs\n",
      "2020A&A...633L..10T \t 56 \t Cosmology from large-scale structure. Constraining ΛCDM with BOSS\n",
      "2019A&A...624A..92K \t 42 \t Towards emulating cosmic shear data: revisiting the calibration of the shear measurements for the Kilo-Degree Survey\n",
      "2018MNRAS.481.1337H \t 29 \t Cosmological simulations for combined-probe analyses: covariance and neighbour-exclusion bias\n",
      "2021A&A...646A.129J \t 34 \t KiDS-1000 methodology: Modelling and inference for joint weak gravitational lensing and spectroscopic galaxy clustering analysis\n",
      "2020A&A...640L..14W \t 29 \t KiDS+VIKING-450: Improved cosmological parameter constraints from redshift calibration with self-organising maps\n",
      "2021A&A...647A.124H \t 26 \t KiDS-1000 catalogue: Redshift distributions and their calibration\n",
      "2021A&A...645A.105G \t 27 \t KiDS-1000 catalogue: Weak gravitational lensing shear measurements\n",
      "2021A&A...649A..88T \t 24 \t KiDS-1000 Cosmology: Constraints beyond flat ΛCDM\n",
      "2018MNRAS.477.4285A \t 22 \t KiDS-i-800: comparing weak gravitational lensing measurements from same-sky surveys\n",
      "2016PASP..128i5001K \t 14 \t The Impact of Interpixel Capacitance in CMOS Detectors on PSF Shapes and Implications for WFIRST\n",
      "2019MNRAS.487.3715V \t 11 \t Luminous red galaxies in the Kilo-Degree Survey: selection with broad-band photometry and weak lensing measurements\n",
      "2020A&A...642A.158B \t 13 \t Testing gravity using galaxy-galaxy lensing and clustering amplitudes in KiDS-1000, BOSS, and 2dFLenS\n",
      "2019A&A...622A..90G \t 13 \t The dependence of intrinsic alignment of galaxies on wavelength using KiDS and GAMA\n",
      "2020A&A...633A..89X \t 8 \t A gravitational lensing detection of filamentary structures connecting luminous red galaxies\n",
      "2016PASP..128j4001P \t 10 \t The Effect of Detector Nonlinearity on WFIRST PSF Profiles for Weak Gravitational Lensing Measurements\n",
      "2020A&A...635A.139E \t 9 \t Euclid preparation. VI. Verifying the performance of cosmic shear experiments\n",
      "2015MNRAS.449.3597K \t 9 \t The impact of cosmic variance on simulating weak lensing surveys\n",
      "2020arXiv200813154V \t 8 \t Clustering of red-sequence galaxies in the fourth data release ofthe Kilo-Degree Survey\n",
      "2020A&A...642A..83D \t 6 \t KiDS+GAMA: The weak lensing calibrated stellar-to-halo mass relation of central and satellite galaxies\n",
      "2021A&A...649A.146R \t 5 \t Strong detection of the CMB lensing and galaxy weak lensing cross-correlation from ACT-DR4, Planck Legacy, and KiDS-1000\n",
      "2021arXiv210207701Y \t 5 \t Probing galaxy bias and intergalactic gas pressure with KiDS Galaxies-tSZ-CMB lensing cross-correlations\n",
      "2021A&A...649A..81N \t 4 \t Photometric selection and redshifts for quasars in the Kilo-Degree Survey Data Release 4\n",
      "2020A&A...640A..59L \t 3 \t KiDS+VIKING+GAMA: Testing semi-analytic models of galaxy evolution with galaxy-galaxy-galaxy lensing\n",
      "2016EL....11557005K \t 3 \t Persistent entanglement in a class of eigenstates of quantum Heisenberg spin glasses\n",
      "2021arXiv210106010B \t 3 \t Bright galaxy sample in the Kilo-Degree Survey Data Release 4: selection, photometric redshifts, and physical properties\n",
      "2021A&A...646A..73S \t 3 \t Tightening weak lensing constraints on the ellipticity of galaxy-scale dark matter haloes\n",
      "2021arXiv210509545R \t 2 \t Geometry vs growth: Internal consistency of the flat {\\Lambda}CDM model with KiDS-1000\n",
      "2021A&A...646A.175L \t 1 \t KiDS+VIKING-450: An internal-consistency test for cosmic shear tomography with a colour-based split of source galaxies\n",
      "2021MNRAS.502.4048K \t 1 \t Mitigating the effects of undersampling in weak lensing shear estimation with metacalibration\n",
      "2021A&A...646A.124H \t 1 \t Accounting for object detection bias in weak gravitational lensing studies\n",
      "2021A&A...650A.113B \t 1 \t The weak lensing radial acceleration relation: Constraining modified gravity and cold dark matter theories with KiDS-1000\n",
      "2020A&A...638C...2E \t 1 \t Euclid preparation. VI. Verifying the Performance of Cosmic Shear Experiments (Corrigendum)\n",
      "2021arXiv210700136L \t 1 \t The three-year shear catalog of the Subaru Hyper Suprime-Cam SSP Survey\n",
      "2021A&A...647A.185G \t 0 \t Halo shapes constrained from a pure sample of central galaxies in KiDS-1000\n",
      "2021A&A...651A..76Y \t 0 \t Probing galaxy bias and intergalactic gas pressure with KiDS Galaxies-tSZ-CMB lensing cross-correlations\n",
      "\n",
      "Total number of citations =  1126\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "## Ensure that the Orcid iDs are consistent and create a single orcid key per author\n",
    "for paper in publications:\n",
    "    nauth = len(paper['author'])\n",
    "    paper['orcid'] = []\n",
    "    for aid in range(nauth):\n",
    "        orcid = (paper['orcid_pub'][aid], paper.get('orcid_user','-'*nauth)[aid], paper.get('orcid_other','-'*nauth)[aid])\n",
    "        orcid = [orc for orc in orcid if orc!='-']\n",
    "        if len(orcid):\n",
    "            all((orc==orcid[0] for orc in orcid))\n",
    "            paper['orcid'].append(orcid[0])\n",
    "        else:\n",
    "            paper['orcid'].append('-')\n",
    "        if verbose:\n",
    "            print(paper['author'][aid], paper['orcid_pub'][aid], paper.get('orcid_user','-'*nauth)[aid], paper.get('orcid_other','-'*nauth)[aid])\n",
    "            print(paper['author'][aid], paper.get('orcid')[aid])\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This would have been an excellent exercise to use a mini database, with a Publications table and an Authors table. But for my purpose, this seemed like an overkill and I use basic Python structures like `dict` and `list`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## Obtain the complete list of co-authors (including self), along with their unique ORCID iDs.\n",
    "coauthors = {}\n",
    "for paper in publications:\n",
    "    for auth, orc in zip(paper['author'], paper['orcid']):\n",
    "        std_name = standardize_names(auth)\n",
    "        coauthors[std_name] = orc if orc!='-' else coauthors.get(std_name, None)\n",
    "if verbose:\n",
    "    print(\"\\nName of the co-authors \\t\\t ORCID iD \\n \")\n",
    "    for coauth in sorted(coauthors.keys()):\n",
    "        print(coauth, '\\t\\t', coauthors[coauth])"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately, many of my co-authors have not provided their ORCID iD. We will have to find common authors by name. ORCID iD will only serve as further validation where applicable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"The following authors have the same last name:\")\n",
    "cntr = Counter([name.split(',')[0] for name in coauthors.keys()])\n",
    "for coauth in coauthors:\n",
    "    if cntr[coauth.split(',')[0]] > 1:\n",
    "        print(coauth, '\\t', coauthors[coauth])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following authors have the same last name:\n",
      "Choi,+A \t None\n",
      "Armstrong,+B \t None\n",
      "Taylor,+A \t None\n",
      "Taylor,+E \t 0000-0002-5522-9107\n",
      "Choi,+S \t None\n",
      "Li,+S \t 0000-0001-9952-7408\n",
      "Li,+X \t None\n",
      "Armstrong,+R \t None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define an empty dictionary to contain the number of independent citations. Loop over the above publications, query the independent citations and count them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%%time\n",
    "fq = \"property%3Aarticle\"\n",
    "fl = \"author,title,bibcode\"\n",
    "rows = 500\n",
    "for eid, entity in enumerate(js['response']['docs']):\n",
    "    independent_authors, independent_orcid = [], []\n",
    "    bibcode = entity['bibcode'].replace('&','%26')\n",
    "    condition = ''\n",
    "    for auth in entity['author']:\n",
    "        name = standardize_names(auth)\n",
    "        if name is None: continue\n",
    "        condition+= f\"+-author:%22{name}%22\"\n",
    "    url = f\"{base_url}q=citations(bibcode%3A{bibcode}){condition}&fq={fq}&fl={fl}&rows={rows}\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    jstmp = r.json()\n",
    "    independent_authors += [standardize_names(paper['author']) for paper in jstmp['response']['docs']]\n",
    "    nauth = len(entity['author'])\n",
    "    if check_orcid:\n",
    "        # Get all coauthor orcid ids\n",
    "        coauthor_orcid = entity.get('orcid_pub',['-'])+entity.get('orcid_user',['-'])+entity.get('orcid_other',['-'])\n",
    "        for cite in jstmp['response']['docs']:\n",
    "            independent_orcid += cite.get('orcid_user',['-'])+cite.get('orcid_pub',['-'])+cite.get('orcid_other',['-'])\n",
    "\n",
    "        independent_orcid = set(independent_orcid)\n",
    "        coauthor_orcid = set(coauthor_orcid)\n",
    "        assert(independent_orcid.intersection(coauthor_orcid).issubset({'-'}))\n",
    "\n",
    "    js['response']['docs'][eid]['independent_citation_count'] = jstmp['response']['numFound']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 774 ms, sys: 51.6 ms, total: 825 ms\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## Print the complete list of queried papers, with independent citations counts for each\n",
    "def print_independent_citation_counts(refereed_only=True, verbose=False):\n",
    "    print(\"Complete list of queried papers\")\n",
    "    print(\"\\t   Bibcode       #Cites #Independent cites \\t Title\\n\")\n",
    "    citation_counts, independent_citation_counts = 0, 0\n",
    "    kids_citation_counts = 0\n",
    "    for paper in publications:\n",
    "        if refereed_only and 'NOT REFEREED' in paper['property']:\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(paper['bibcode'], '\\t', paper['citation_count'], paper['independent_citation_count'], '\\t', paper['title'][0])\n",
    "        citation_counts += paper['citation_count']\n",
    "        independent_citation_counts += paper['independent_citation_count']\n",
    "        if 'kids' in paper['title'][0].lower():\n",
    "            kids_citation_counts += paper['independent_citation_count']\n",
    "    print(\"\\nTotal number of citations = \", citation_counts)\n",
    "    print(\"\\nTotal number of independent citations = \", independent_citation_counts)\n",
    "    print(\"\\nTotal number of independent citations from KiDS papers = \", kids_citation_counts)\n",
    "    return independent_citation_counts"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "independent_citation_counts = print_independent_citation_counts(refereed_only=False, verbose=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Complete list of queried papers\n",
      "\t   Bibcode       #Cites #Independent cites \t Title\n",
      "\n",
      "2020A&A...633A..69H \t 193 122 \t KiDS+VIKING-450: Cosmic shear tomography with optical and infrared data\n",
      "2014ApJS..212....5M \t 120 64 \t The Third Gravitational Lensing Accuracy Testing (GREAT3) Challenge Handbook\n",
      "2021A&A...646A.140H \t 124 77 \t KiDS-1000 Cosmology: Multi-probe weak gravitational lensing and spectroscopic galaxy clustering constraints\n",
      "2021A&A...645A.104A \t 113 84 \t KiDS-1000 cosmology: Cosmic shear constraints and comparison between two point statistics\n",
      "2020A&A...638L...1J \t 93 71 \t KiDS+VIKING-450 and DES-Y1 combined: Cosmology with cosmic shear\n",
      "2020A&A...634A.127A \t 59 34 \t KiDS+VIKING-450 and DES-Y1 combined: Mitigating baryon feedback uncertainty with COSEBIs\n",
      "2020A&A...633L..10T \t 56 37 \t Cosmology from large-scale structure. Constraining ΛCDM with BOSS\n",
      "2019A&A...624A..92K \t 42 15 \t Towards emulating cosmic shear data: revisiting the calibration of the shear measurements for the Kilo-Degree Survey\n",
      "2018MNRAS.481.1337H \t 29 12 \t Cosmological simulations for combined-probe analyses: covariance and neighbour-exclusion bias\n",
      "2021A&A...646A.129J \t 34 10 \t KiDS-1000 methodology: Modelling and inference for joint weak gravitational lensing and spectroscopic galaxy clustering analysis\n",
      "2020A&A...640L..14W \t 29 17 \t KiDS+VIKING-450: Improved cosmological parameter constraints from redshift calibration with self-organising maps\n",
      "2021A&A...647A.124H \t 26 8 \t KiDS-1000 catalogue: Redshift distributions and their calibration\n",
      "2021A&A...645A.105G \t 27 12 \t KiDS-1000 catalogue: Weak gravitational lensing shear measurements\n",
      "2021A&A...649A..88T \t 24 9 \t KiDS-1000 Cosmology: Constraints beyond flat ΛCDM\n",
      "2018MNRAS.477.4285A \t 22 2 \t KiDS-i-800: comparing weak gravitational lensing measurements from same-sky surveys\n",
      "2016PASP..128i5001K \t 14 3 \t The Impact of Interpixel Capacitance in CMOS Detectors on PSF Shapes and Implications for WFIRST\n",
      "2019MNRAS.487.3715V \t 11 4 \t Luminous red galaxies in the Kilo-Degree Survey: selection with broad-band photometry and weak lensing measurements\n",
      "2020A&A...642A.158B \t 13 6 \t Testing gravity using galaxy-galaxy lensing and clustering amplitudes in KiDS-1000, BOSS, and 2dFLenS\n",
      "2019A&A...622A..90G \t 13 1 \t The dependence of intrinsic alignment of galaxies on wavelength using KiDS and GAMA\n",
      "2020A&A...633A..89X \t 8 4 \t A gravitational lensing detection of filamentary structures connecting luminous red galaxies\n",
      "2016PASP..128j4001P \t 10 5 \t The Effect of Detector Nonlinearity on WFIRST PSF Profiles for Weak Gravitational Lensing Measurements\n",
      "2020A&A...635A.139E \t 9 4 \t Euclid preparation. VI. Verifying the performance of cosmic shear experiments\n",
      "2015MNRAS.449.3597K \t 9 4 \t The impact of cosmic variance on simulating weak lensing surveys\n",
      "2020arXiv200813154V \t 8 4 \t Clustering of red-sequence galaxies in the fourth data release ofthe Kilo-Degree Survey\n",
      "2020A&A...642A..83D \t 6 3 \t KiDS+GAMA: The weak lensing calibrated stellar-to-halo mass relation of central and satellite galaxies\n",
      "2021A&A...649A.146R \t 5 1 \t Strong detection of the CMB lensing and galaxy weak lensing cross-correlation from ACT-DR4, Planck Legacy, and KiDS-1000\n",
      "2021arXiv210207701Y \t 5 4 \t Probing galaxy bias and intergalactic gas pressure with KiDS Galaxies-tSZ-CMB lensing cross-correlations\n",
      "2021A&A...649A..81N \t 4 1 \t Photometric selection and redshifts for quasars in the Kilo-Degree Survey Data Release 4\n",
      "2020A&A...640A..59L \t 3 1 \t KiDS+VIKING+GAMA: Testing semi-analytic models of galaxy evolution with galaxy-galaxy-galaxy lensing\n",
      "2016EL....11557005K \t 3 1 \t Persistent entanglement in a class of eigenstates of quantum Heisenberg spin glasses\n",
      "2021arXiv210106010B \t 3 0 \t Bright galaxy sample in the Kilo-Degree Survey Data Release 4: selection, photometric redshifts, and physical properties\n",
      "2021A&A...646A..73S \t 3 0 \t Tightening weak lensing constraints on the ellipticity of galaxy-scale dark matter haloes\n",
      "2021arXiv210509545R \t 2 1 \t Geometry vs growth: Internal consistency of the flat {\\Lambda}CDM model with KiDS-1000\n",
      "2021A&A...646A.175L \t 1 0 \t KiDS+VIKING-450: An internal-consistency test for cosmic shear tomography with a colour-based split of source galaxies\n",
      "2021MNRAS.502.4048K \t 1 0 \t Mitigating the effects of undersampling in weak lensing shear estimation with metacalibration\n",
      "2021A&A...646A.124H \t 1 0 \t Accounting for object detection bias in weak gravitational lensing studies\n",
      "2021A&A...650A.113B \t 1 0 \t The weak lensing radial acceleration relation: Constraining modified gravity and cold dark matter theories with KiDS-1000\n",
      "2020A&A...638C...2E \t 1 1 \t Euclid preparation. VI. Verifying the Performance of Cosmic Shear Experiments (Corrigendum)\n",
      "2021arXiv210700136L \t 1 0 \t The three-year shear catalog of the Subaru Hyper Suprime-Cam SSP Survey\n",
      "2021A&A...647A.185G \t 0 0 \t Halo shapes constrained from a pure sample of central galaxies in KiDS-1000\n",
      "2021A&A...651A..76Y \t 0 0 \t Probing galaxy bias and intergalactic gas pressure with KiDS Galaxies-tSZ-CMB lensing cross-correlations\n",
      "\n",
      "Total number of citations =  1126\n",
      "\n",
      "Total number of independent citations =  622\n",
      "\n",
      "Total number of independent citations from KiDS papers =  463\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voila! We have calculated independent citation counts for each referee publication of mine, and the total number of independent citations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, calculate the citations from one specific author"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def citations_counts_from(other_author, verbose=False):\n",
    "    \"\"\"\n",
    "    Count the number of citations from a particular author.\n",
    "    \"\"\"\n",
    "    other_author = standardize_names(other_author)\n",
    "    other_citation_count = 0\n",
    "    # https://ui.adsabs.harvard.edu/search/filter_author_facet_hier_fq_author=AND&filter_author_facet_hier_fq_author=author_facet_hier%3A%220%2FTroxel%2C%20M%22&fq=%7B!type%3Daqp%20v%3D%24fq_author%7D&fq_author=(author_facet_hier%3A%220%2FTroxel%2C%20M%22)&q=citations(bibcode%3A2015MNRAS.449.3597K)&sort=date%20desc%2C%20bibcode%20desc&p_=0\n",
    "    fq = \"property%3Aarticle\"\n",
    "    fl = \"author,title,bibcode\"\n",
    "    rows = 500\n",
    "    for eid, entity in enumerate(js['response']['docs']):\n",
    "        independent_authors, independent_orcid = [], []\n",
    "        bibcode = entity['bibcode'].replace('&','%26')\n",
    "        condition = ''\n",
    "        url = (f\"{base_url}filter_author_facet_hier_fq_author=AND&\"\n",
    "                \"filter_author_facet_hier_fq_author=author_facet_hier%3A%220%2F\"\n",
    "                f\"{other_author}&fq=%7B!type%3Daqp%20v%3D%24fq_author%7D&\"\n",
    "                f\"fq_author=(author_facet_hier%3A%220%2F{other_author})&\"\n",
    "                f\"q=citations({bibcode})&sort=date%20desc%2C%20bibcode%20desc&p_=0&rows=500\")\n",
    "        r = requests.get(url, headers=headers)\n",
    "        jstmp = r.json()\n",
    "        if verbose:\n",
    "            print(bibcode, len(jstmp['response']['docs']))\n",
    "        other_citation_count += len(jstmp['response']['docs'])\n",
    "\n",
    "    return other_citation_count\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "other_author = \"Troxel, M\"\n",
    "other_citation_count = citations_counts_from(other_author)\n",
    "print(f\"Number of citations from {other_author} = {other_citation_count}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of citations from Troxel, M = 105\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Consistency check\n",
    "\n",
    "If you are the other author, then the citations from you to your papers should match exactly the number of self-citations that is reported in the metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "other_citation_count = citations_counts_from(\"Kannawadi, A\")\n",
    "# to pass a dictionary in the request payload, convert it to a string first using the json package\n",
    "payload = {\"bibcodes\": [paper['bibcode'] for paper in publications], \\\n",
    "           \"types\":[\"citation_stats\"], \"histograms\":[\"citations\"]}\n",
    "metrics = requests.post(\"https://api.adsabs.harvard.edu/v1/metrics\", \\\n",
    "                 headers={\"Authorization\": \"Bearer \" + token, \"Content-type\": \"application/json\"}, \\\n",
    "                 data=json.dumps(payload))\n",
    "metrics = metrics.json()\n",
    "print(\"Number of self-citations counted from ADS metrics = \", metrics[\"citation stats\"][\"number of self-citations\"])\n",
    "print(\"Number of self-ctiations counted from our loop = \", other_citation_count)\n",
    "assert metrics[\"citation stats\"][\"number of self-citations\"] == other_citation_count\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of self-citations counted from ADS metrics =  185\n",
      "Number of self-ctiations counted from our loop =  185\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('ssc--VxenSW5': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "interpreter": {
   "hash": "60cb5b6a0e0a40f12a0b6f394627794b0cb1d66db9335cabc448aaf203ffc8f4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}